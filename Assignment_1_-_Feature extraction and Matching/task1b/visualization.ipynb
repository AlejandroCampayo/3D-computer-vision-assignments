{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1b Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreloading if import packages are changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up python path \n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "_img1 = cv2.imread(\"../data/CheckerWarp.png\")\n",
    "_color1 = cv2.cvtColor(_img1, cv2.COLOR_BGR2RGB)\n",
    "_gray1 = cv2.cvtColor(_color1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "img1 = torch.tensor(_img1, device=device) / 255\n",
    "color1 = torch.tensor(_color1, device=device) / 255\n",
    "gray1 = torch.tensor(_gray1, device=device) / 255\n",
    "\n",
    "I = gray1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Convolution Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from task1b.blob import convolution_kernel\n",
    "\n",
    "k = convolution_kernel(5, device)\n",
    "plt.imshow(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(I, keypoints):\n",
    "    cv2_keypoints = [] \n",
    "    for i in range(0, keypoints.shape[0]):\n",
    "        pos = keypoints[i,0:2]\n",
    "        scale = keypoints[i,2]\n",
    "        cv2_keypoints.append(cv2.KeyPoint(pos[1].item(), pos[0].item(), scale.item()))\n",
    "    result = cv2.drawKeypoints(\n",
    "        I, \n",
    "        cv2_keypoints, \n",
    "        0, \n",
    "        (-1, -1, -1), \n",
    "        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "    )\n",
    "    plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect keypoints on test pattern\n",
    "\n",
    "from task1b.blob import SIFTDetector\n",
    "\n",
    "d = SIFTDetector() \n",
    "keypoints = d.detect_keypoints(I, threshold=0.7)\n",
    "\n",
    "show_keypoints(_gray1, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect keypoints on real image\n",
    "\n",
    "# PLEASE NOTE: You will see blobs in homogeneous areas as well. The full SIFT descriptor requires to \n",
    "# filter these out by checking if sufficient structure is present in the image (you don't need to do this). \n",
    "\n",
    "_img1 = cv2.imread(\"../data/Chess.png\")\n",
    "_color1 = cv2.cvtColor(_img1, cv2.COLOR_BGR2RGB)\n",
    "_gray1 = cv2.cvtColor(_color1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "img1 = torch.tensor(_img1, device=device) / 255\n",
    "color1 = torch.tensor(_color1, device=device) / 255\n",
    "gray1 = torch.tensor(_gray1, device=device) / 255\n",
    "\n",
    "I = gray1\n",
    "\n",
    "keypoints = d.detect_keypoints(I, threshold=0.6)\n",
    "\n",
    "show_keypoints(_gray1, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detect keypoints on real image\n",
    "\n",
    "# PLEASE NOTE: You will see blobs in homogeneous areas as well. The full SIFT descriptor requires to \n",
    "# filter these out by checking if sufficient structure is present in the image (you don't need to do this). \n",
    "\n",
    "_img1 = cv2.imread(\"../data/NotreDame1.jpg\")\n",
    "_color1 = cv2.cvtColor(_img1, cv2.COLOR_BGR2RGB)\n",
    "_gray1 = cv2.cvtColor(_color1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "img1 = torch.tensor(_img1, device=device) / 255\n",
    "color1 = torch.tensor(_color1, device=device) / 255\n",
    "gray1 = torch.tensor(_gray1, device=device) / 255\n",
    "\n",
    "I = gray1\n",
    "\n",
    "keypoints = d.detect_keypoints(I, threshold=0.4)\n",
    "\n",
    "show_keypoints(_gray1, keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
